{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3d88cfa",
   "metadata": {},
   "source": [
    "# LOGS and data prep for SANDBOMICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbff9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scanpy in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (1.11.5)\n",
      "Requirement already satisfied: anndata>=0.8 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (0.11.4)\n",
      "Requirement already satisfied: h5py>=3.7.0 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (3.15.1)\n",
      "Requirement already satisfied: joblib in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (1.5.2)\n",
      "Requirement already satisfied: legacy-api-wrap>=1.4.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (1.5)\n",
      "Requirement already satisfied: matplotlib>=3.7.5 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (3.10.8)\n",
      "Requirement already satisfied: natsort in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.7.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (3.4.2)\n",
      "Requirement already satisfied: numba!=0.62.0rc1,>=0.57.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (0.62.1)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (2.2.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (25.0)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (2.3.3)\n",
      "Requirement already satisfied: patsy!=1.0.0 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (1.0.2)\n",
      "Requirement already satisfied: pynndescent>=0.5.13 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (0.5.13)\n",
      "Requirement already satisfied: scikit-learn>=1.1.3 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (1.7.2)\n",
      "Requirement already satisfied: scipy>=1.8.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (1.15.2)\n",
      "Requirement already satisfied: seaborn>=0.13.2 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (0.13.2)\n",
      "Requirement already satisfied: session-info2 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (0.2.3)\n",
      "Requirement already satisfied: statsmodels>=0.14.5 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (0.14.5)\n",
      "Requirement already satisfied: tqdm in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (4.15.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.6 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scanpy) (0.5.9.post2)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from anndata>=0.8->scanpy) (1.12.0)\n",
      "Requirement already satisfied: exceptiongroup in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from anndata>=0.8->scanpy) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from matplotlib>=3.7.5->scanpy) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from matplotlib>=3.7.5->scanpy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from matplotlib>=3.7.5->scanpy) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from matplotlib>=3.7.5->scanpy) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from matplotlib>=3.7.5->scanpy) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from matplotlib>=3.7.5->scanpy) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from matplotlib>=3.7.5->scanpy) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from numba!=0.62.0rc1,>=0.57.1->scanpy) (0.45.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->scanpy) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages (from scikit-learn>=1.1.3->scanpy) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scanpy\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83683760",
   "metadata": {},
   "source": [
    "my earlier data (h5ad matrices) have more information about the dat inside the matrices and i woudl not like to loose it (like IDs, molecular subtypes etc), i would like to add this information to csv files generated from RECODE analysis\n",
    "Example on smallest TN sample:\n",
    "- Old object: adata_triplenegative_epithelial_improved.h5ad\n",
    "    - 7561 cells × 33514 genes, ~93.5% sparse.\n",
    "    - adata.obs[\"molecular_subtype\"], sample_name, etc. already defined.\n",
    "\n",
    "- New RECODE CSV: TN_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\n",
    "    - 7561 rows × 16380 genes (after dropping the index column).\n",
    "    - Same cells, fewer genes, denoised counts.\n",
    "\n",
    "- So for clustering/UMAP in the SANBOMICS notebook, best is:\n",
    "    - Build a new AnnData from the RECODE expression.\n",
    "    - Copy the obs metadata (including molecular_subtype) from the old adata onto this new one, matched by cell ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55399529",
   "metadata": {},
   "source": [
    "okay, this seems a bit more complicated then i have expected: kernel keeps crashing becuase there is a big amount of data. i tried to loop and automate - didn't work, i have tried not looping and work with each sample separately - didn't wokr\n",
    "\n",
    "so now i will try to:\n",
    "extract the columns i need from the big h5ad dataset, this should create a smaller dataset then the one i had initially so it should not crash. \n",
    "then i gonna take the csv file i have created with RECODE which is already smaller and merge it with the file i have created via extracting the metadata from the dataset. \n",
    "what i could do, is first try it with the smallest TN sample: in this case i can save the extracted metadata from h5ad dataset and run a check first (like read rows and columns and check if they match expectations), if the check is good, i could merge with the existing RECODE csv file, then check again if everything is like i want. \n",
    "if it works, i could create a class and loop over 5 other samples so it is automated, however in this case, it won't be neccessary to save the file only with metadata since it will take space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c5ab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TN metadata to: /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn/TN_metadata_only.csv\n",
      "   sample_name     sample_type molecular_subtype   cell_type  \\\n",
      "0      TN-0126  TripleNegative            Normal  Epithelial   \n",
      "2      TN-0126  TripleNegative              LumA  Epithelial   \n",
      "4      TN-0126  TripleNegative            Normal  Epithelial   \n",
      "9      TN-0126  TripleNegative            Normal  Epithelial   \n",
      "15     TN-0126  TripleNegative            Normal  Epithelial   \n",
      "\n",
      "    epithelial_score  immune_score      geo_id cell_id  \n",
      "0               26.0      7.250000  GSM4909281       0  \n",
      "2                5.0      0.923077  GSM4909281       2  \n",
      "4               20.0      1.750000  GSM4909281       4  \n",
      "9                3.6      1.375000  GSM4909281       9  \n",
      "15              11.8      8.428571  GSM4909281      15  \n",
      "(7561, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "\n",
    "#Load original TN AnnData\n",
    "adata_tn = sc.read_h5ad(\n",
    "    \"/triumvirate/home/alexarol/breast_cancer_analysis/results/adata_triplenegative_epithelial_improved.h5ad\"\n",
    ")\n",
    "adata_tn.obs_names_make_unique()\n",
    "\n",
    "#Select obs columns you care about\n",
    "obs_cols = [\n",
    "    \"sample_name\",\n",
    "    \"sample_type\",\n",
    "    \"molecular_subtype\",\n",
    "    \"cell_type\",\n",
    "    \"epithelial_score\",\n",
    "    \"immune_score\",\n",
    "    \"geo_id\",\n",
    "]\n",
    "\n",
    "meta_tn = adata_tn.obs[obs_cols].copy()\n",
    "meta_tn[\"cell_id\"] = meta_tn.index.astype(str)\n",
    "\n",
    "#Save metadata to a small CSV\n",
    "meta_tn_path = \"/triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn/TN_metadata_only.csv\"\n",
    "meta_tn.to_csv(meta_tn_path, index=False)\n",
    "\n",
    "print(\"Saved TN metadata to:\", meta_tn_path)\n",
    "print(meta_tn.head())\n",
    "print(meta_tn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50749e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expr rows: 7561\n",
      "Meta rows: 7561\n",
      "Common cell_ids: 7561\n",
      "Merged shape: (7561, 16388)\n",
      "  sample_name     sample_type molecular_subtype   cell_type  epithelial_score  \\\n",
      "0     TN-0126  TripleNegative            Normal  Epithelial              26.0   \n",
      "1     TN-0126  TripleNegative              LumA  Epithelial               5.0   \n",
      "2     TN-0126  TripleNegative            Normal  Epithelial              20.0   \n",
      "3     TN-0126  TripleNegative            Normal  Epithelial               3.6   \n",
      "4     TN-0126  TripleNegative            Normal  Epithelial              11.8   \n",
      "\n",
      "   immune_score      geo_id cell_id  AL627309.1  AL669831.5  ...  MT-ND4L  \\\n",
      "0      7.250000  GSM4909281       0           0           0  ...        5   \n",
      "1      0.923077  GSM4909281       2           0           0  ...        0   \n",
      "2      1.750000  GSM4909281       4           0           0  ...        2   \n",
      "3      1.375000  GSM4909281       9           0           0  ...        2   \n",
      "4      8.428571  GSM4909281      15           0           1  ...        2   \n",
      "\n",
      "   MT-ND4  MT-ND5  MT-ND6  MT-CYB  BX004987.1  AC011043.1  AC007325.4  \\\n",
      "0     184      30       0      95           0           0           0   \n",
      "1      43       1       1      22           0           0           0   \n",
      "2      69       4       0      65           0           0           0   \n",
      "3     198      10       0      89           0           1           0   \n",
      "4     114      11       0      98           0           0           0   \n",
      "\n",
      "   AL354822.1  AC004556.1  \n",
      "0           0           0  \n",
      "1           0           0  \n",
      "2           0           0  \n",
      "3           0           0  \n",
      "4           0           0  \n",
      "\n",
      "[5 rows x 16388 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load RECODE expression CSV\n",
    "expr_path = \"/triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn/TN_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\"\n",
    "expr_df = pd.read_csv(expr_path, dtype={0: str})\n",
    "\n",
    "expr_df.rename(columns={expr_df.columns[0]: \"cell_id\"}, inplace=True)\n",
    "\n",
    "#Load TN metadata\n",
    "meta_tn_path = \"/triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn/TN_metadata_only.csv\"\n",
    "meta_tn = pd.read_csv(meta_tn_path, dtype={\"cell_id\": str})\n",
    "\n",
    "#Check that cell IDs overlap as expected\n",
    "print(\"Expr rows:\", expr_df.shape[0])\n",
    "print(\"Meta rows:\", meta_tn.shape[0])\n",
    "\n",
    "common_ids = set(expr_df[\"cell_id\"]) & set(meta_tn[\"cell_id\"])\n",
    "print(\"Common cell_ids:\", len(common_ids))\n",
    "\n",
    "#Merge metadata + expression (metadata on the left)\n",
    "merged_tn = meta_tn.merge(expr_df, on=\"cell_id\", how=\"inner\")\n",
    "\n",
    "print(\"Merged shape:\", merged_tn.shape)\n",
    "print(merged_tn.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9dd464",
   "metadata": {},
   "source": [
    "- Expr rows: 7561, Meta rows: 7561, Common cell_ids: 7561 → all cells match; nothing lost.\n",
    "- Merged shape: (7561, 16388) →\n",
    "- 7 metadata columns (sample_name, sample_type, molecular_subtype, cell_type, epithelial_score, immune_score, geo_id),\n",
    "- 16380 gene columns = 7 + 1 + 16380 = 16388 total.\n",
    "- The head shows exactly what i want: each row has subtype (Normal, LumA, etc.), sample, scores, plus all gene counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d231e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged TN RECODE+metadata CSV to: /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn/TN_RECODE_with_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "merged_out = \"/triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn/TN_RECODE_with_metadata.csv\"\n",
    "merged_tn.to_csv(merged_out, index=False)\n",
    "print(\"Saved merged TN RECODE+metadata CSV to:\", merged_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8e43e",
   "metadata": {},
   "source": [
    "will try looping it for other 5 samples -. this diddint work, it crashes - i will try just savin gteh metadata in csv files without merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9298b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_metadata_from_h5ad(\n",
    "    orig_h5ad_path: str,\n",
    "    out_meta_csv_path: str,\n",
    "    obs_cols=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Load a full h5ad, extract selected obs columns + cell_id,\n",
    "    and save as a small metadata CSV.\n",
    "    \"\"\"\n",
    "    if obs_cols is None:\n",
    "        obs_cols = [\n",
    "            \"sample_name\",\n",
    "            \"sample_type\",\n",
    "            \"molecular_subtype\",\n",
    "            \"cell_type\",\n",
    "            \"epithelial_score\",\n",
    "            \"immune_score\",\n",
    "            \"geo_id\",\n",
    "        ]\n",
    "\n",
    "    adata = sc.read_h5ad(orig_h5ad_path)\n",
    "    adata.obs_names_make_unique()\n",
    "\n",
    "    meta = adata.obs[obs_cols].copy()\n",
    "    meta[\"cell_id\"] = meta.index.astype(str)\n",
    "\n",
    "    meta.to_csv(out_meta_csv_path, index=False)\n",
    "    print(f\"Saved metadata to: {out_meta_csv_path}  (rows: {meta.shape[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94e8235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting metadata for Normal...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata to: /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/normal/Normal_metadata_only.csv  (rows: 83522)\n",
      "Exporting metadata for ER_Positive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata to: /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/er_positive/ER_Positive_metadata_only.csv  (rows: 91908)\n",
      "Exporting metadata for HER2_Positive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata to: /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/her2_positive/HER2_Positive_metadata_only.csv  (rows: 19693)\n",
      "Exporting metadata for TN_BRCA1...\n",
      "Saved metadata to: /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn_brca1/TN_BRCA1_metadata_only.csv  (rows: 14186)\n",
      "Exporting metadata for BRCA1_preneoplastic...\n",
      "Saved metadata to: /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/preneoplastic/BRCA1_preneoplastic_metadata_only.csv  (rows: 7644)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n",
      "/triumvirate/home/alexarol/.conda/envs/breast_cancer_scrnaseq/lib/python3.10/site-packages/anndata/_core/anndata.py:1756: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "base = \"/triumvirate/home/alexarol/breast_cancer_analysis\"\n",
    "\n",
    "meta_targets = {\n",
    "    \"Normal\": {\n",
    "        \"orig_h5ad\": f\"{base}/results/adata_normal_epithelial_improved.h5ad\",\n",
    "        \"out_meta\": f\"{base}/results/recode_outputs/normal/Normal_metadata_only.csv\",\n",
    "    },\n",
    "    \"ER_Positive\": {\n",
    "        \"orig_h5ad\": f\"{base}/results/adata_er_positive_epithelial_improved.h5ad\",\n",
    "        \"out_meta\": f\"{base}/results/recode_outputs/er_positive/ER_Positive_metadata_only.csv\",\n",
    "    },\n",
    "    \"HER2_Positive\": {\n",
    "        \"orig_h5ad\": f\"{base}/results/adata_her2_positive_epithelial_improved.h5ad\",\n",
    "        \"out_meta\": f\"{base}/results/recode_outputs/her2_positive/HER2_Positive_metadata_only.csv\",\n",
    "    },\n",
    "    \"TN_BRCA1\": {\n",
    "        \"orig_h5ad\": f\"{base}/results/adata_triplenegative_brca1_epithelial_improved.h5ad\",\n",
    "        \"out_meta\": f\"{base}/results/recode_outputs/tn_brca1/TN_BRCA1_metadata_only.csv\",\n",
    "    },\n",
    "    \"BRCA1_preneoplastic\": {\n",
    "        \"orig_h5ad\": f\"{base}/results/adata_brca1_preneoplastic_epithelial_improved.h5ad\",\n",
    "        \"out_meta\": f\"{base}/results/recode_outputs/preneoplastic/BRCA1_preneoplastic_metadata_only.csv\",\n",
    "    },\n",
    "}\n",
    "\n",
    "for label, paths in meta_targets.items():\n",
    "    print(f\"Exporting metadata for {label}...\")\n",
    "    export_metadata_from_h5ad(\n",
    "        orig_h5ad_path=paths[\"orig_h5ad\"],\n",
    "        out_meta_csv_path=paths[\"out_meta\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4e8e91",
   "metadata": {},
   "source": [
    "now i will proceed with SANDBOMICS before builindg the networx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b020fa23",
   "metadata": {},
   "source": [
    "# SANDBOMICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8104390a",
   "metadata": {},
   "source": [
    "Working per “analysis type” and looping over samples - this is a good moment to decide how you handle HVGs inside that SANBOMICS‑style workflow\n",
    "​\n",
    "1. Using the SANBOMICS notebook with RECODE\n",
    "- Start each analysis section from a RECODE expression matrix (per sample), loaded as an AnnData.\n",
    "- Skip parts that assume raw sequencing counts (alignment, raw QC, very aggressive filtering).\n",
    "- Keep:\n",
    "    -   library‑size normalization (for visualization),\n",
    "    - log1p transform,\n",
    "    - PCA, neighbors, UMAP, Leiden, marker plots, etc.\n",
    "​\n",
    "​- Run these steps in loops over 6 RECODE AnnData objects inside each “chapter” (QC, UMAP, clustering, etc.)\n",
    "- This way, SANBOMICS is a visualization + exploration layer on top of RECODE, not a second denoising pipeline.\n",
    "\n",
    "2. Where to put HVG selection\n",
    "- Effectively have two layers of HVG logic now:\n",
    "    - RECODE already gave you sets like *_sig_genes_atleast2 and the *_cellsxgenes_forWGCNA CSVs, which are biologically enriched and denoising‑aware.\n",
    "    - Scanpy/SANBOMICS normally calls sc.pp.highly_variable_genes on the raw (or normalized) data to pick, e.g., 2000 HVGs for clustering.\n",
    "    - Given the RECODE paper explicitly recommends using the denoised variance as the basis for HVGs, and the new HVG method is designed exactly for that, i are already doing the “hard” selection in a principled way.\n",
    "\n",
    "- For networks and final analyses (correlations, WGCNA‑like, etc.):\n",
    "    - I will use RECODE‑based HVGs and gene sets that you control (e.g. 3000 HVGs per condition, from my variance ranks).\n",
    "- For clustering/UMAP only in SANBOMICS:\n",
    "    - I can either:\n",
    "        - reuse the same RECODE HVG subset (e.g. limit .var to my chosen HVGs and run PCA/UMAP on those), or\n",
    "        - let Scanpy pick a local HVG set for clustering only, but keep that separate from the network HVGs.\n",
    "\n",
    "I already have a nice TN example with 3000 HVGs and reasonable sparsity, I’d keep HVG limit under my control, not fully delegated to Scanpy:\n",
    "- Decide per condition: e.g. 3000–4000 HVGs for both clustering and networks.\n",
    "- Implement that as a simple variance‑based ranking on the RECODE matrix per sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d57b9d",
   "metadata": {},
   "source": [
    "my thoughts: fix a core HVG set now, use it for Scanpy visualization to verify data quality, then use the same genes for correlation and networks, and later expand HVG size for sensitivity analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f32c2",
   "metadata": {},
   "source": [
    "then i should do the 3000 as baseline and dohe SANDBOMICS (Scanpy), \n",
    "then i have the vizialuzation of the data (it shoudl be alright, i mean the vizualization should show me the quility of the data, but i hope it is alright since i have done the RECODE and now i will choose the core 3000 highly variable genes which will always saty as the core, those are the most important genes) \n",
    "and i can run correlation, once the correlation is done for those genes i will have a ready matrix to build the networks\n",
    "and yeah, for networks i will be using the approch where: i start with combined analysis to identify shared and genotype-associated modules \n",
    "    (i need to think about this, i have 1 healthy one, 1 precancerous (for BRCA1) and 4 cancerous\n",
    "    so if i abbreviate all teh data this way: \n",
    "        Normal = N, \n",
    "        Er_Positive = E, \n",
    "        HER2_positive = H, \n",
    "        TripleNegative = TN, \n",
    "        TripleNegative_BRCA1 = TNB, \n",
    "        BRCA1_preneoplastic = PreB; \n",
    "    i could maybe do these pairs: \n",
    "        N + PreB, \n",
    "        PreB+TNB,\n",
    "        N+E, \n",
    "        N+H, \n",
    "        N+TN, \n",
    "        N+TNB; \n",
    "    and then i do group specific approach and i build networks for:\n",
    "        N, \n",
    "        E, \n",
    "        H, \n",
    "        TN, \n",
    "        TNB, \n",
    "        PreB \n",
    "            (maybe even specify it for molecular subtypes as well?9\n",
    "        and i don't know, but maybe i can somehow create a combined version of N+PreB+TNB?\n",
    "\n",
    "then we build networks, analyze them and probably repeat the same process few more times with different limit for HVGs?\n",
    "\n",
    "CORE: For each: RECODE → 3000 HVGs → correlation across cells → network → modules + hubs\n",
    "\n",
    "ISSUE: ecause my groups differ in size (e.g. TN very small vs Normal huge in cell count), for combined analyses I may want to downsample cells per group to balance representation and avoid one group dominating correlations\n",
    "- Balancing HVGs and balancing cells solve different issues; using the same number of HVGs does not fix the imbalance in cell counts between groups\n",
    "- HVG choice controls which genes I analyze.\n",
    "- Downsampling controls how many cells per group contribute to the correlation estimates.\n",
    "\n",
    "In a combined analysis (e.g. N + TN):\n",
    "- If Normal has 80k cells and TN has 7k, most pairwise correlations will be driven by patterns in the Normal cells simply because they dominate the sample size, even if you use the same 3000 HVGs.\n",
    "- Downsampling (e.g. take 7k cells from Normal as well) gives each group more equal “weight” in the correlation structure, so genotype‑associated modules are easier to see and interpret.\n",
    "\n",
    "So:\n",
    "- For per‑group networks (N only, TN only, etc.), no downsampling is needed; I just use all cells for that group.\n",
    "- For combined networks (N + TN, N + PreB, etc.), it is still wise to consider per‑group downsampling to avoid one group dominating, even though the HVG set is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b1350",
   "metadata": {},
   "source": [
    "## Setting up SANDBOMICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e544d3",
   "metadata": {},
   "source": [
    "Define:\n",
    "- A dictionary of my 6 RECODE CSV paths.\n",
    "- A function to load one CSV into AnnData (no metadata for now).\n",
    "- A function to select HVGs (e.g. top 3000 by variance) per adata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1426ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/triumvirate/home/alexarol/breast_cancer_analysis\"\n",
    "\n",
    "recode_csvs = {\n",
    "    \"TN\": f\"{base}/results/recode_outputs/tn/TN_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\",\n",
    "    \"Normal\": f\"{base}/results/recode_outputs/normal/Normal_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\",\n",
    "    \"ER_Positive\": f\"{base}/results/recode_outputs/er_positive/ER_Positive_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\",\n",
    "    \"HER2_Positive\": f\"{base}/results/recode_outputs/her2_positive/HER2_Positive_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\",\n",
    "    \"TN_BRCA1\": f\"{base}/results/recode_outputs/tn_brca1/TN_BRCA1_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\",\n",
    "    \"BRCA1_preneoplastic\": f\"{base}/results/recode_outputs/preneoplastic/BRCA1_preneoplastic_RECODE_sig_genes_cellsxgenes_forWGCNA.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b4545",
   "metadata": {},
   "source": [
    "I will not doo doublet reduction and removal via svVI/SOLO (explained on paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d520aa",
   "metadata": {},
   "source": [
    "## Flaggin mitochondial genes\n",
    "- What: Identify mitochondrial genes (MT- prefix) and quantify mitochondrial counts per cell.\n",
    "- Why: High mitochondrial fraction is a classic sign of low‑quality or stressed cells; i want to see these metrics and later use them for QC filtering and plots.\n",
    "- Input: RECODE‑denoised expression matrices (cells × genes) loaded as AnnData, one per condition.\n",
    "- Output: For each adata:\n",
    "    - adata.var['mt'] marking mitochondrial genes.\n",
    "    - adata.obs['total_counts'], adata.obs['n_genes_by_counts'], adata.obs['pct_counts_mt'] (and other QC metrics).\n",
    "- Usage later: i will use these QC metrics to visualize data quality (violin plots, UMAP coloring) and to define cell‑level filters before network construction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390414f7",
   "metadata": {},
   "source": [
    "kernel crashes on big smaples, i need a different approach\n",
    "The memory issue comes from adata = sc.AnnData(X=expr.values) on very large expr, not from adding the mt column.\n",
    "\n",
    "because of this, i need to change approach, here is what i am thinkging about: \n",
    "- i need to select HVGs before proceesing, there is not other  i am aware of, but if i am selecting HVGs for one of the samples, i should do it for all and only then proceed further\n",
    "- but what i am thinking about now, that it could not be a good idea to downsample everything to such a little amount as 3000 genes, i could downsample it later\n",
    "- but since i know, that this flagging worked with 7561 cells and 16380 genes i could use this amount as starting maximum point?\n",
    "- it is probaly not the amount of genes which is the problem, but the amount cells,  and even if we choose the most highly variable genes the cell amount would not go down, no?\n",
    "\n",
    "Two separate things matter now for memory and for biology:\n",
    "- Memory / crash risk\n",
    "- Statistical meaning (cells vs genes)\n",
    "\n",
    "The kernel crashes because creating AnnData(X=expr.values) for very large samples allocates a big dense array in RAM: roughly n_cells × n_genes.\n",
    "\n",
    "Reducing genes (HVGs) shrinks this product.\n",
    "\n",
    "Reducing cells would shrink it too, but that does change the biology because you’d lose cells.\n",
    "\n",
    "So:\n",
    "- Yes, HVG selection reduces memory.\n",
    "- No, HVGs do not reduce the number of cells; they only cut columns. this is my logic\n",
    "\n",
    "chunking big samples would not work now, because: \n",
    "- Break per‑sample QC summaries (e.g. global distributions of pct_counts_mt).\n",
    "- Make it hard to compare cells across the whole sample in UMAP / clustering.\n",
    "\n",
    "So i should not split the cell dimension for analysis; if i need to process data in pieces for intermediate computations (like computing variances in chunks), that’s fine, but the final AnnData per sample should still contain all cells.\n",
    "\n",
    "THUS, now i will: \n",
    "1: HVG selection per sample directly from the RECODE CSVs\n",
    "    For each sample:\n",
    "    - Read the CSV in pandas.\n",
    "    - Compute per‑gene variance (or RECODE HVG score) across cells.\n",
    "    - Choose a relatively generous number, e.g. 6000 HVGs per sample as an upper bound (since flagging worked with TN sample) - maybe if it counts eveything too fast i can even make the number higher??\n",
    "    - Save the list of HVGs per sample (plain text or CSV of gene names).\n",
    "\n",
    "2: Load only HVGs into AnnData for SANBOMICS\n",
    "    For each sample:    \n",
    "    - Read the CSV again, but immediately subset columns to [\"cell_id\"] + hvg_genes.\n",
    "    - Now AnnData.X is n_cells × n_HVGs (e.g. 80k × 6000 for Normal instead of 80k × 16k).\n",
    "    - Run mito flagging + QC + UMAP on these HVGs.\n",
    "\n",
    "3 (later): network HVGs\n",
    "- From those 6000 per sample, define a 3000‑gene core (top by variance) for correlation and networks.\n",
    "- Use the same core for both clustering and network analysis per condition if you want.\n",
    "\n",
    "This keeps:\n",
    "- Cell count intact (no downsampling yet).\n",
    "- A consistent HVG pipeline across all 6 samples.\n",
    "- Memory under control by cutting the gene dimension before building dense AnnData objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6deb46ff",
   "metadata": {},
   "source": [
    "### per‑sample HVG preselection from RECODE CSVs\n",
    "- What: For each sample, compute per‑gene variance directly from the RECODE CSV and keep the top n_top genes.\n",
    "- Why: This reduces the gene dimension before building AnnData, so large samples (Normal, ER+) fit in memory, while keeping the most informative genes.\n",
    "- Input: RECODE CSV (cells × genes, first column = cell_id).\n",
    "- Output: A list of HVG gene names per sample, which i then use to load a smaller AnnData and run mito/QC/UMAP.\n",
    "\n",
    "I will start with n_top = 6000 and later try 7000, 8000, etc., by changing the parameter.\n",
    "\n",
    "yes, this would have worked - but kernel keeps crashing if i loop\n",
    "so what i wiull do is that i will do is i will run analysisn on each sample separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab7297b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting HVGs for TN from /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/tn/TN_RECODE_sig_genes_cellsxgenes_forWGCNA.csv ...\n",
      "  TN: selected 6000 HVGs\n",
      "Selecting HVGs for Normal from /triumvirate/home/alexarol/breast_cancer_analysis/results/recode_outputs/normal/Normal_RECODE_sig_genes_cellsxgenes_forWGCNA.csv ...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_top_hvgs_from_csv(csv_path: str, n_top: int = 6000) -> pd.Index:\n",
    "    df = pd.read_csv(csv_path, dtype={0: str})\n",
    "    expr = df.iloc[:, 1:]\n",
    "    var = expr.var(axis=0)\n",
    "    top_genes = var.sort_values(ascending=False).head(n_top).index\n",
    "    return top_genes\n",
    "\n",
    "n_top_hvg = 6000\n",
    "hvg_genes: Dict[str, pd.Index] = {}\n",
    "\n",
    "for label, path in recode_csvs.items():\n",
    "    print(f\"Selecting HVGs for {label} from {path} ...\")\n",
    "    top_genes = get_top_hvgs_from_csv(path, n_top=n_top_hvg)\n",
    "    hvg_genes[label] = top_genes\n",
    "    print(f\"  {label}: selected {len(top_genes)} HVGs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a5696",
   "metadata": {},
   "source": [
    "at this point kernel crashes too much, i will do the SANDBOMICS of each smaple in separete notebook named: 06_RECODE_SANDBOMICS_[sample_name].ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615116b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breast_cancer_scrnaseq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
